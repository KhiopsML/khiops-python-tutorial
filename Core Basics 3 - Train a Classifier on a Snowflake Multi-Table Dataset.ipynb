{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Basics 3: Train a Classifier on a Snowflake Multi-Table Dataset\n",
    "\n",
    "In this notebook, we learn how to train a classifier with a more complex multi-table data where a secondary table is itself a parent table of another table (ie. snowflake schema). It is highly recommended to see the _Basics 1_ and _Basics 2_  lessons if you are not familiar with Khiops.\n",
    "\n",
    "Make sure you have installed [Khiops](https://khiops.org/setup/) and [Khiops Visualization](https://khiops.org/setup/visualization/).\n",
    "\n",
    "We start by importing Khiops, checking its installation and defining some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "from khiops import core as kh\n",
    "\n",
    "# Define helper functions\n",
    "def peek(file_path, n=10):\n",
    "    \"\"\"Shows the first n lines of a file\"\"\"\n",
    "    with open(file_path, encoding=\"utf8\", errors=\"replace\") as file:\n",
    "        for line in file.readlines()[:n]:\n",
    "            print(line, end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def os_open(path):\n",
    "    \"\"\"Opens a file or directory with its default application\"\"\"\n",
    "    if platform.system() == \"Windows\":\n",
    "        os.startfile(path)\n",
    "    elif platform.system() == \"Darwin\":\n",
    "        subprocess.call([\"open\", path])\n",
    "    else:\n",
    "        subprocess.call([\"xdg-open\", path])\n",
    "\n",
    "\n",
    "# If there are any issues you may Khiops status with the following command\n",
    "# kh.get_runner().print_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Multi-Table Classifier\n",
    "\n",
    "We'll train a multi-table classifier on a extension of dataset `AccidentsSummary` that we used in the previous notebook  _Sklearn Basics 2_. This dataset `Accidents` contains two additional tables `Place` and `User` and is organized in the following relational snowflake schema:\n",
    "\n",
    "```\n",
    "Accident\n",
    "|\n",
    "| -- 1:n -- Vehicle\n",
    "|             |\n",
    "|             |-- 1:n -- User\n",
    "|\n",
    "| -- 1:1 -- Place\n",
    "```\n",
    "\n",
    "Note that the target variable is `Gravity`.\n",
    "\n",
    "To train the KhiopsClassifier for this setup, this schema must be codified in the dictionary file. Let's check the contents of the `Accidents` dictionary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_dataset_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "accidents_kdic = os.path.join(accidents_dataset_dir, \"Accidents.kdic\")\n",
    "\n",
    "print(f\"Accidents dictionary file location: {accidents_kdic}\")\n",
    "print(\"\")\n",
    "peek(accidents_kdic, n=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following differences in comparison with the dictionary of dataset `AccidentsSummary`.\n",
    "\n",
    "- The schema for the main table contains one extra special variable defined with the statement `Entity(Place) Place` which indicate a `1:1` relationship between `Accident` and `Place` tables.\n",
    "- The main table `Accident` and entity `Place` have the same key `AccidentId`. Table `Vehicle` and its child table `User` have two keys `AccidentId` and `VehicleId`.\n",
    "\n",
    "Now let's store the location of the tables and peek their contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_data_file = os.path.join(accidents_dataset_dir, \"Accidents.txt\")\n",
    "print(f\"Accidents data table: {accidents_data_file}\")\n",
    "print(\"\")\n",
    "peek(accidents_data_file)\n",
    "\n",
    "vehicles_data_file = os.path.join(accidents_dataset_dir, \"Vehicles.txt\")\n",
    "print(f\"Vehicles data table: {vehicles_data_file}\")\n",
    "print(\"\")\n",
    "peek(vehicles_data_file)\n",
    "\n",
    "places_data_file = os.path.join(accidents_dataset_dir, \"Places.txt\")\n",
    "print(f\"Places data table: {places_data_file}\")\n",
    "print(\"\")\n",
    "peek(places_data_file)\n",
    "\n",
    "users_data_file = os.path.join(accidents_dataset_dir, \"Users.txt\")\n",
    "print(f\"Users data table: {users_data_file}\")\n",
    "print(\"\")\n",
    "peek(users_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a classifier for the `Accidents` database with 1000 variables\n",
    "\n",
    "The call to the train_predictor is exactly the same as seen before on the exercice of the previous notebook _Sklearn Basics 2_. The only difference is the extension of the dictionary `additional_data_tables`, which contains paths of the additional tables, with two new paths:\n",
    "\n",
    "- Path of entity `Place` is ``Accident`Place``.\n",
    "- Path of table `User` is ``Accident`Vehicles`Users``.\n",
    "\n",
    "\n",
    "Same as previously, we'll ask Khiops to create 1000 additional features with its multi-table AutoML mode.\n",
    "\n",
    "Do not forget:\n",
    "- The target variable is `Gravity`\n",
    "- Set `max_trees=0`\n",
    "\n",
    "With these considerations, let's now train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_results_dir = os.path.join(\"exercises\", \"Accidents\")\n",
    "accidents_report, accidents_model_kdic = kh.train_predictor(\n",
    "    accidents_kdic,\n",
    "    dictionary_name=\"Accident\",\n",
    "    data_table_path=accidents_data_file,\n",
    "    target_variable=\"Gravity\",\n",
    "    results_dir=accidents_results_dir,\n",
    "    additional_data_tables={\n",
    "        \"Accident`Vehicles\": vehicles_data_file,\n",
    "        \"Accident`Place\": places_data_file,\n",
    "        \"Accident`Vehicles`Users\": users_data_file,\n",
    "    },\n",
    "    max_constructed_variables=1000,\n",
    "    max_trees=0,\n",
    ")\n",
    "print(f\"Accidents report file: {accidents_report}\")\n",
    "print(f\"Accidents modeling dictionary file: {accidents_model_kdic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look to the report\n",
    "Which variables predict well the gravity of an accident?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize uncomment the line below\n",
    "# os_open(accidents_report)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}